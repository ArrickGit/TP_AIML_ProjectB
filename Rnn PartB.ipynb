{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Training for Warpeace_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3046702\n",
      "\"well, prince, so genoa and lucca are now just family estates of the\n",
      "buonapartes. but i warn you, if\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "filename2 = \"./dataset/text_data/warpeace_input.txt\"\n",
    "\n",
    "#raw_text is a string of characters\n",
    "raw_text2 = open(filename2, 'r', encoding='utf-8').read()\n",
    "raw_text2 = raw_text2.lower()\n",
    "\n",
    "print(len(raw_text2))\n",
    "\n",
    "#print the first 100 characters of raw_text\n",
    "print(raw_text2[:100])\n",
    "\n",
    "#print the character at index 5\n",
    "print(raw_text2[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59247\n",
      "these words she greeted prince vasili kuragin, a man of high rank and\n",
      "[132, 190, 24, 2860, 38, 290, 974, 5, 66, 4, 480, 1832, 2]\n",
      "[132, 190]\n",
      "[132, 190, 24]\n",
      "[132, 190, 24, 2860]\n",
      "[132, 190, 24, 2860, 38]\n",
      "[132, 190, 24, 2860, 38, 290]\n",
      "[132, 190, 24, 2860, 38, 290, 974]\n",
      "[132, 190, 24, 2860, 38, 290, 974, 5]\n",
      "[132, 190, 24, 2860, 38, 290, 974, 5, 66]\n",
      "[132, 190, 24, 2860, 38, 290, 974, 5, 66, 4]\n",
      "[132, 190, 24, 2860, 38, 290, 974, 5, 66, 4, 480]\n",
      "[132, 190, 24, 2860, 38, 290, 974, 5, 66, 4, 480, 1832]\n",
      "[132, 190, 24, 2860, 38, 290, 974, 5, 66, 4, 480, 1832, 2]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#this block of codes is for testing only and evaluation only\n",
    "#not necessary for the successful development of RNN model.\n",
    "\n",
    "line2 = raw_text2.split('\\n')\n",
    "print(len(line2))\n",
    "print(line2[10])\n",
    "\n",
    "#arguments in fit_on_texts & texts_to_sequence are list of texts\n",
    "#so need to ensure the texts are in list => need to enclose raw_text in [ ]\n",
    "tokenizer2 = Tokenizer()\n",
    "tokenizer2.fit_on_texts([raw_text2])\n",
    "\n",
    "sequences2 = list()\n",
    "\n",
    "#encoded contains the number of sequences\n",
    "for i in range(10,11):\n",
    "#    encoded = tokenizer.texts_to_sequences([line[i]])[0]\n",
    "    encoded2 = tokenizer2.texts_to_sequences([line2[i]]) [0]\n",
    "   # print(len(line[i])) #number of characters\n",
    "   # print([line[i]])\n",
    "    print(encoded2)\n",
    "    \n",
    "    for j in range(1, len(encoded2)):\n",
    "        sequence2 = encoded2[:j+1]\n",
    "        print(sequence2)\n",
    "        sequences2.append(sequence2)\n",
    "    \n",
    "print(len(sequences2))\n",
    "\n",
    "#print([line])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17816\n",
      "Total Sequences: 491219\n",
      "[5169, 973, 4, 394]\n",
      "[5169, 973, 4, 394, 2]\n",
      "Max Sequence Length: 19\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0 5169  973    4  394]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      " 5169  973    4  394    2]\n",
      "(491219, 19)\n"
     ]
    }
   ],
   "source": [
    "tokenizer2 = Tokenizer()\n",
    "\n",
    "#arguments in fit_on_texts & texts_to_sequence are list of texts\n",
    "#so to ensure the texts are in list => need to enclose raw_text in [ ]\n",
    "tokenizer2.fit_on_texts([raw_text2])\n",
    "\n",
    "vocab_size2 = len(tokenizer2.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "print(vocab_size2)\n",
    "\n",
    "sequences2 = list()\n",
    "\n",
    "for line2 in raw_text2.split('\\n'):\n",
    "    encoded2 = tokenizer2.texts_to_sequences([line2])[0]\n",
    "    \n",
    "    for i in range(1, len(encoded2)):\n",
    "        sequence2 = encoded2[:i+1]\n",
    "        sequences2.append(sequence2)\n",
    "        \n",
    "print('Total Sequences: %d' % len(sequences2))\n",
    "\n",
    "print(sequences2[100])\n",
    "print(sequences2[101])\n",
    "#print(sequences2[102])\n",
    "#print(sequences2[103])\n",
    "# pad input sequences\n",
    "max_length2 = max([len(seq2) for seq2 in sequences2])\n",
    "print('Max Sequence Length: %d' % max_length2)\n",
    "sequences2 = pad_sequences(sequences2, maxlen=max_length2, padding='pre')\n",
    "print(sequences2[100])\n",
    "print(sequences2[101])\n",
    "#print(sequences2[102])\n",
    "#print(sequences2[103])\n",
    "print(sequences2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(491219, 18)\n",
      "(491219,)\n",
      "[   0    0    0    0    0    0    0    0    0    0 1142  114 4050   17\n",
      " 1171    1 3783   31   27]\n",
      "[   0    0    0    0    0    0    0    0    0    0 1142  114 4050   17\n",
      " 1171    1 3783   31]\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# split into input and output elements\n",
    "\n",
    "#sequences[:,:-1] => extract all texts except the last text in each line\n",
    "#sequences[:,-1] => extract only the last text in each line\n",
    "X_train2, X_test2 = sequences2[:,:-1],sequences2[:,-1]\n",
    "print(X_train2.shape)\n",
    "print(X_test2.shape)\n",
    "print(sequences2[1000])\n",
    "print(X_train2[1000])\n",
    "print(X_test2[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix2(filepath2, word_index2, embedding_dim2):\n",
    "    vocab_size2 = len(word_index2) + 1  # Adding again 1 because of reserved 0 index\n",
    "    \n",
    "    embedding_matrix2 = np.zeros((vocab_size2, embedding_dim2))\n",
    "\n",
    "    with open(filepath2, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index2:                \n",
    "                idx2 = word_index2[word]\n",
    "                #print(\"found\", idx)\n",
    "                embedding_matrix[idx2] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim2]\n",
    "\n",
    "    return embedding_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17816, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim2 = 100\n",
    "\n",
    "embedding_matrix2 = create_embedding_matrix(\n",
    "    './dataset/glove/glove.6B.100d.txt', \n",
    "    tokenizer2.word_index, embedding_dim2)\n",
    "\n",
    "print(embedding_matrix2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the directory ckpt if it does not exist.\n",
    "#The ckpt directory is used to store the partially trained model\n",
    "import os\n",
    "checkpoint_dir2 = './ckpt2'\n",
    "if not os.path.exists(checkpoint_dir2):\n",
    "    os.makedirs(checkpoint_dir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_or_restore_model2():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints2 = [checkpoint_dir2 + '/' + name\n",
    "                   for name in os.listdir(checkpoint_dir2)]\n",
    "    if checkpoints2:\n",
    "        latest_checkpoint2 = max(checkpoints2, key=os.path.getctime)\n",
    "        print('Restoring from', latest_checkpoint2)\n",
    "        return tf.keras.models.load_model(latest_checkpoint2)\n",
    "    \n",
    "    #create a new model\n",
    "    print('Creating a new model')\n",
    "    return make_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "def make_model2():\n",
    "    model2 = models.Sequential()\n",
    "    model2.add(layers.Embedding(vocab_size2, embedding_dim2, \n",
    "                           weights=[embedding_matrix2], \n",
    "                           input_length=max_length-1, \n",
    "                           trainable=True))\n",
    "    model2.add(layers.LSTM(50, return_sequences=True))  \n",
    "    model2.add(layers.LSTM(50))\n",
    "    model2.add(layers.Dense(vocab_size2, activation='softmax'))\n",
    "    print(model2.summary())\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 15, 100)           1781600   \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 15, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 17816)             908616    \n",
      "=================================================================\n",
      "Total params: 2,740,616\n",
      "Trainable params: 2,740,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "\n",
    "model2 = make_or_restore_model2()\n",
    "\n",
    "early_stop2 = tf.keras.callbacks.EarlyStopping(patience=5, monitor='accuracy')\n",
    "\n",
    "    # This callback checkpoint saves a SavedModel every epoch.\n",
    "    # We include the epoch and accuracy in the file name.\n",
    "checkpoint2 = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + '/weights-improvement-{epoch:02d}-{accuracy:.2f}.hdf5', \n",
    "        monitor='accuracy',verbose=1,\n",
    "        save_best_only=False, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 6.0521 - accuracy: 0.1153\n",
      "Epoch 00001: saving model to ./ckpt\\weights-improvement-01-0.12.hdf5\n",
      "15351/15351 [==============================] - 676s 44ms/step - loss: 6.0521 - accuracy: 0.1153\n",
      "Epoch 2/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 5.5373 - accuracy: 0.1488\n",
      "Epoch 00002: saving model to ./ckpt\\weights-improvement-02-0.15.hdf5\n",
      "15351/15351 [==============================] - 749s 49ms/step - loss: 5.5373 - accuracy: 0.1488\n",
      "Epoch 3/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 5.3293 - accuracy: 0.1614 ETA: 1s\n",
      "Epoch 00003: saving model to ./ckpt\\weights-improvement-03-0.16.hdf5\n",
      "15351/15351 [==============================] - 753s 49ms/step - loss: 5.3293 - accuracy: 0.1614\n",
      "Epoch 4/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 5.1940 - accuracy: 0.1693\n",
      "Epoch 00004: saving model to ./ckpt\\weights-improvement-04-0.17.hdf5\n",
      "15351/15351 [==============================] - 750s 49ms/step - loss: 5.1940 - accuracy: 0.1693\n",
      "Epoch 5/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 5.0900 - accuracy: 0.1763\n",
      "Epoch 00005: saving model to ./ckpt\\weights-improvement-05-0.18.hdf5\n",
      "15351/15351 [==============================] - 740s 48ms/step - loss: 5.0900 - accuracy: 0.1763\n",
      "Epoch 6/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 5.0063 - accuracy: 0.1815\n",
      "Epoch 00006: saving model to ./ckpt\\weights-improvement-06-0.18.hdf5\n",
      "15351/15351 [==============================] - 748s 49ms/step - loss: 5.0063 - accuracy: 0.1815\n",
      "Epoch 7/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.9399 - accuracy: 0.1866\n",
      "Epoch 00007: saving model to ./ckpt\\weights-improvement-07-0.19.hdf5\n",
      "15351/15351 [==============================] - 742s 48ms/step - loss: 4.9399 - accuracy: 0.1866\n",
      "Epoch 8/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.8838 - accuracy: 0.1909\n",
      "Epoch 00008: saving model to ./ckpt\\weights-improvement-08-0.19.hdf5\n",
      "15351/15351 [==============================] - 766s 50ms/step - loss: 4.8838 - accuracy: 0.1909\n",
      "Epoch 9/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.8327 - accuracy: 0.1941\n",
      "Epoch 00009: saving model to ./ckpt\\weights-improvement-09-0.19.hdf5\n",
      "15351/15351 [==============================] - 757s 49ms/step - loss: 4.8327 - accuracy: 0.1941\n",
      "Epoch 10/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.7857 - accuracy: 0.1980\n",
      "Epoch 00010: saving model to ./ckpt\\weights-improvement-10-0.20.hdf5\n",
      "15351/15351 [==============================] - 760s 49ms/step - loss: 4.7857 - accuracy: 0.1980\n",
      "Epoch 11/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.7408 - accuracy: 0.2012\n",
      "Epoch 00011: saving model to ./ckpt\\weights-improvement-11-0.20.hdf5\n",
      "15351/15351 [==============================] - 769s 50ms/step - loss: 4.7408 - accuracy: 0.2012\n",
      "Epoch 12/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.7003 - accuracy: 0.2045\n",
      "Epoch 00012: saving model to ./ckpt\\weights-improvement-12-0.20.hdf5\n",
      "15351/15351 [==============================] - 763s 50ms/step - loss: 4.7003 - accuracy: 0.2045\n",
      "Epoch 13/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.6634 - accuracy: 0.2078\n",
      "Epoch 00013: saving model to ./ckpt\\weights-improvement-13-0.21.hdf5\n",
      "15351/15351 [==============================] - 767s 50ms/step - loss: 4.6635 - accuracy: 0.2078\n",
      "Epoch 14/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.6322 - accuracy: 0.2107\n",
      "Epoch 00014: saving model to ./ckpt\\weights-improvement-14-0.21.hdf5\n",
      "15351/15351 [==============================] - 762s 50ms/step - loss: 4.6322 - accuracy: 0.2107\n",
      "Epoch 15/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.6032 - accuracy: 0.2133\n",
      "Epoch 00015: saving model to ./ckpt\\weights-improvement-15-0.21.hdf5\n",
      "15351/15351 [==============================] - 772s 50ms/step - loss: 4.6032 - accuracy: 0.2133\n",
      "Epoch 16/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.5768 - accuracy: 0.2161\n",
      "Epoch 00016: saving model to ./ckpt\\weights-improvement-16-0.22.hdf5\n",
      "15351/15351 [==============================] - 773s 50ms/step - loss: 4.5768 - accuracy: 0.2161\n",
      "Epoch 17/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.5501 - accuracy: 0.2184\n",
      "Epoch 00017: saving model to ./ckpt\\weights-improvement-17-0.22.hdf5\n",
      "15351/15351 [==============================] - 771s 50ms/step - loss: 4.5501 - accuracy: 0.2184\n",
      "Epoch 18/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.5237 - accuracy: 0.2209\n",
      "Epoch 00018: saving model to ./ckpt\\weights-improvement-18-0.22.hdf5\n",
      "15351/15351 [==============================] - 776s 51ms/step - loss: 4.5237 - accuracy: 0.2209\n",
      "Epoch 19/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.4998 - accuracy: 0.2236\n",
      "Epoch 00019: saving model to ./ckpt\\weights-improvement-19-0.22.hdf5\n",
      "15351/15351 [==============================] - 775s 50ms/step - loss: 4.4999 - accuracy: 0.2236\n",
      "Epoch 20/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.4758 - accuracy: 0.2255\n",
      "Epoch 00020: saving model to ./ckpt\\weights-improvement-20-0.23.hdf5\n",
      "15351/15351 [==============================] - 777s 51ms/step - loss: 4.4758 - accuracy: 0.2255\n",
      "Epoch 21/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.4551 - accuracy: 0.2281\n",
      "Epoch 00021: saving model to ./ckpt\\weights-improvement-21-0.23.hdf5\n",
      "15351/15351 [==============================] - 764s 50ms/step - loss: 4.4551 - accuracy: 0.2281\n",
      "Epoch 22/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.4370 - accuracy: 0.2299\n",
      "Epoch 00022: saving model to ./ckpt\\weights-improvement-22-0.23.hdf5\n",
      "15351/15351 [==============================] - 765s 50ms/step - loss: 4.4370 - accuracy: 0.2299\n",
      "Epoch 23/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.4206 - accuracy: 0.2317\n",
      "Epoch 00023: saving model to ./ckpt\\weights-improvement-23-0.23.hdf5\n",
      "15351/15351 [==============================] - 761s 50ms/step - loss: 4.4206 - accuracy: 0.2317\n",
      "Epoch 24/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.4047 - accuracy: 0.2331\n",
      "Epoch 00024: saving model to ./ckpt\\weights-improvement-24-0.23.hdf5\n",
      "15351/15351 [==============================] - 764s 50ms/step - loss: 4.4047 - accuracy: 0.2331\n",
      "Epoch 25/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.3900 - accuracy: 0.2343\n",
      "Epoch 00025: saving model to ./ckpt\\weights-improvement-25-0.23.hdf5\n",
      "15351/15351 [==============================] - 772s 50ms/step - loss: 4.3900 - accuracy: 0.2343\n",
      "Epoch 26/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.3702 - accuracy: 0.2363\n",
      "Epoch 00026: saving model to ./ckpt\\weights-improvement-26-0.24.hdf5\n",
      "15351/15351 [==============================] - 764s 50ms/step - loss: 4.3701 - accuracy: 0.2363\n",
      "Epoch 27/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.3498 - accuracy: 0.2386\n",
      "Epoch 00027: saving model to ./ckpt\\weights-improvement-27-0.24.hdf5\n",
      "15351/15351 [==============================] - 762s 50ms/step - loss: 4.3498 - accuracy: 0.2386\n",
      "Epoch 28/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.3322 - accuracy: 0.2400\n",
      "Epoch 00028: saving model to ./ckpt\\weights-improvement-28-0.24.hdf5\n",
      "15351/15351 [==============================] - 759s 49ms/step - loss: 4.3322 - accuracy: 0.2400\n",
      "Epoch 29/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.3166 - accuracy: 0.2414\n",
      "Epoch 00029: saving model to ./ckpt\\weights-improvement-29-0.24.hdf5\n",
      "15351/15351 [==============================] - 765s 50ms/step - loss: 4.3166 - accuracy: 0.2414\n",
      "Epoch 30/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.3026 - accuracy: 0.2429\n",
      "Epoch 00030: saving model to ./ckpt\\weights-improvement-30-0.24.hdf5\n",
      "15351/15351 [==============================] - 771s 50ms/step - loss: 4.3025 - accuracy: 0.2429\n",
      "Epoch 31/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.2911 - accuracy: 0.2444\n",
      "Epoch 00031: saving model to ./ckpt\\weights-improvement-31-0.24.hdf5\n",
      "15351/15351 [==============================] - 765s 50ms/step - loss: 4.2911 - accuracy: 0.2444\n",
      "Epoch 32/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.2791 - accuracy: 0.2452\n",
      "Epoch 00032: saving model to ./ckpt\\weights-improvement-32-0.25.hdf5\n",
      "15351/15351 [==============================] - 766s 50ms/step - loss: 4.2792 - accuracy: 0.2452\n",
      "Epoch 33/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.2675 - accuracy: 0.2462\n",
      "Epoch 00033: saving model to ./ckpt\\weights-improvement-33-0.25.hdf5\n",
      "15351/15351 [==============================] - 769s 50ms/step - loss: 4.2675 - accuracy: 0.2462\n",
      "Epoch 34/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.2547 - accuracy: 0.2475\n",
      "Epoch 00034: saving model to ./ckpt\\weights-improvement-34-0.25.hdf5\n",
      "15351/15351 [==============================] - 766s 50ms/step - loss: 4.2547 - accuracy: 0.2475\n",
      "Epoch 35/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.2440 - accuracy: 0.2486\n",
      "Epoch 00035: saving model to ./ckpt\\weights-improvement-35-0.25.hdf5\n",
      "15351/15351 [==============================] - 773s 50ms/step - loss: 4.2439 - accuracy: 0.2486\n",
      "Epoch 36/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.2325 - accuracy: 0.2498\n",
      "Epoch 00036: saving model to ./ckpt\\weights-improvement-36-0.25.hdf5\n",
      "15351/15351 [==============================] - 770s 50ms/step - loss: 4.2325 - accuracy: 0.2498\n",
      "Epoch 37/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.2209 - accuracy: 0.2514\n",
      "Epoch 00037: saving model to ./ckpt\\weights-improvement-37-0.25.hdf5\n",
      "15351/15351 [==============================] - 776s 51ms/step - loss: 4.2209 - accuracy: 0.2514\n",
      "Epoch 38/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.2120 - accuracy: 0.2515\n",
      "Epoch 00038: saving model to ./ckpt\\weights-improvement-38-0.25.hdf5\n",
      "15351/15351 [==============================] - 767s 50ms/step - loss: 4.2121 - accuracy: 0.2515\n",
      "Epoch 39/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.2040 - accuracy: 0.2527\n",
      "Epoch 00039: saving model to ./ckpt\\weights-improvement-39-0.25.hdf5\n",
      "15351/15351 [==============================] - 772s 50ms/step - loss: 4.2040 - accuracy: 0.2527\n",
      "Epoch 40/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.1964 - accuracy: 0.2541\n",
      "Epoch 00040: saving model to ./ckpt\\weights-improvement-40-0.25.hdf5\n",
      "15351/15351 [==============================] - 778s 51ms/step - loss: 4.1964 - accuracy: 0.2541\n",
      "Epoch 41/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.1899 - accuracy: 0.2547\n",
      "Epoch 00041: saving model to ./ckpt\\weights-improvement-41-0.25.hdf5\n",
      "15351/15351 [==============================] - 771s 50ms/step - loss: 4.1899 - accuracy: 0.2547\n",
      "Epoch 42/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.1822 - accuracy: 0.2552\n",
      "Epoch 00042: saving model to ./ckpt\\weights-improvement-42-0.26.hdf5\n",
      "15351/15351 [==============================] - 844s 55ms/step - loss: 4.1822 - accuracy: 0.2552\n",
      "Epoch 43/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.1771 - accuracy: 0.2563\n",
      "Epoch 00043: saving model to ./ckpt\\weights-improvement-43-0.26.hdf5\n",
      "15351/15351 [==============================] - 815s 53ms/step - loss: 4.1771 - accuracy: 0.2563\n",
      "Epoch 44/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.1704 - accuracy: 0.2567\n",
      "Epoch 00044: saving model to ./ckpt\\weights-improvement-44-0.26.hdf5\n",
      "15351/15351 [==============================] - 784s 51ms/step - loss: 4.1704 - accuracy: 0.2567\n",
      "Epoch 45/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.1658 - accuracy: 0.2572\n",
      "Epoch 00045: saving model to ./ckpt\\weights-improvement-45-0.26.hdf5\n",
      "15351/15351 [==============================] - 781s 51ms/step - loss: 4.1658 - accuracy: 0.2572\n",
      "Epoch 46/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.1604 - accuracy: 0.2581\n",
      "Epoch 00046: saving model to ./ckpt\\weights-improvement-46-0.26.hdf5\n",
      "15351/15351 [==============================] - 784s 51ms/step - loss: 4.1604 - accuracy: 0.2581\n",
      "Epoch 47/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.1555 - accuracy: 0.2584\n",
      "Epoch 00047: saving model to ./ckpt\\weights-improvement-47-0.26.hdf5\n",
      "15351/15351 [==============================] - 775s 50ms/step - loss: 4.1555 - accuracy: 0.2584\n",
      "Epoch 48/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.1516 - accuracy: 0.2593\n",
      "Epoch 00048: saving model to ./ckpt\\weights-improvement-48-0.26.hdf5\n",
      "15351/15351 [==============================] - 781s 51ms/step - loss: 4.1516 - accuracy: 0.2593\n",
      "Epoch 49/50\n",
      "15350/15351 [============================>.] - ETA: 0s - loss: 4.1460 - accuracy: 0.2595\n",
      "Epoch 00049: saving model to ./ckpt\\weights-improvement-49-0.26.hdf5\n",
      "15351/15351 [==============================] - 781s 51ms/step - loss: 4.1459 - accuracy: 0.2595\n",
      "Epoch 50/50\n",
      "15351/15351 [==============================] - ETA: 0s - loss: 4.1417 - accuracy: 0.2600\n",
      "Epoch 00050: saving model to ./ckpt\\weights-improvement-50-0.26.hdf5\n",
      "15351/15351 [==============================] - 781s 51ms/step - loss: 4.1417 - accuracy: 0.2600\n"
     ]
    }
   ],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "history2 = model2.fit(X_train2, X_test2, epochs=50, verbose=1, callbacks= [early_stop2, checkpoint2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is for WarPeace_input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15351/15351 [==============================] - 186s 12ms/step - loss: 3.9770 - accuracy: 0.2753\n",
      "Training Accuracy: 0.2753\n"
     ]
    }
   ],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "#print(history.history.keys())\n",
    "loss, accuracy = model2.evaluate(X_train2, X_test2, verbose=True)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Warpeace_input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "model2.save(\"./model/warpeacegeneration_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and Training for alice_in_wonderland.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148181\n",
      "  alice was beginning to get very tired of sitting by her sister\n",
      "on the bank, and of having nothing \n",
      "c\n"
     ]
    }
   ],
   "source": [
    "filename = \"./dataset/text_data/alice_in_wonderland.txt\"\n",
    "\n",
    "#raw_text is a string of characters\n",
    "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "print(len(raw_text))\n",
    "\n",
    "#print the first 100 characters of raw_text\n",
    "print(raw_text[:100])\n",
    "\n",
    "#print the character at index 5\n",
    "print(raw_text[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3576\n",
      "rabbit with pink eyes ran close by her.\n",
      "[108, 21, 1494, 155, 231, 279, 74, 17]\n",
      "[108, 21]\n",
      "[108, 21, 1494]\n",
      "[108, 21, 1494, 155]\n",
      "[108, 21, 1494, 155, 231]\n",
      "[108, 21, 1494, 155, 231, 279]\n",
      "[108, 21, 1494, 155, 231, 279, 74]\n",
      "[108, 21, 1494, 155, 231, 279, 74, 17]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "#this block of codes is for testing only and evaluation only\n",
    "#not necessary for the successful development of RNN model.\n",
    "\n",
    "line = raw_text.split('\\n')\n",
    "print(len(line))\n",
    "print(line[10])\n",
    "\n",
    "#arguments in fit_on_texts & texts_to_sequence are list of texts\n",
    "#so need to ensure the texts are in list => need to enclose raw_text in [ ]\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([raw_text])\n",
    "\n",
    "sequences = list()\n",
    "\n",
    "#encoded contains the number of sequences\n",
    "for i in range(10,11):\n",
    "#    encoded = tokenizer.texts_to_sequences([line[i]])[0]\n",
    "    encoded = tokenizer.texts_to_sequences([line[i]]) [0]\n",
    "   # print(len(line[i])) #number of characters\n",
    "   # print([line[i]])\n",
    "    print(encoded)\n",
    "    \n",
    "    for j in range(1, len(encoded)):\n",
    "        sequence = encoded[:j+1]\n",
    "        print(sequence)\n",
    "        sequences.append(sequence)\n",
    "    \n",
    "print(len(sequences))\n",
    "\n",
    "#print([line])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2638\n",
      "Total Sequences: 25049\n",
      "[108, 21, 1494, 155]\n",
      "[108, 21, 1494, 155, 231]\n",
      "Max Sequence Length: 16\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0  108   21\n",
      " 1494  155]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0  108   21 1494\n",
      "  155  231]\n",
      "(25049, 16)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "#arguments in fit_on_texts & texts_to_sequence are list of texts\n",
    "#so to ensure the texts are in list => need to enclose raw_text in [ ]\n",
    "tokenizer.fit_on_texts([raw_text])\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "print(vocab_size)\n",
    "\n",
    "sequences = list()\n",
    "\n",
    "for line in raw_text.split('\\n'):\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "    \n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "print(sequences[100])\n",
    "print(sequences[101])\n",
    "#print(sequences[102])\n",
    "#print(sequences[103])\n",
    "# pad input sequences\n",
    "max_length = max([len(seq) for seq in sequences])\n",
    "print('Max Sequence Length: %d' % max_length)\n",
    "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
    "print(sequences[100])\n",
    "print(sequences[101])\n",
    "#print(sequences[102])\n",
    "#print(sequences[103])\n",
    "print(sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25049, 15)\n",
      "(25049,)\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0 868 128   1]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0 868 128]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# split into input and output elements\n",
    "\n",
    "#sequences[:,:-1] => extract all texts except the last text in each line\n",
    "#sequences[:,-1] => extract only the last text in each line\n",
    "X_train, X_test = sequences[:,:-1],sequences[:,-1]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(sequences[1000])\n",
    "print(X_train[1000])\n",
    "print(X_test[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:                \n",
    "                idx = word_index[word]\n",
    "                #print(\"found\", idx)\n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2638, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "embedding_matrix = create_embedding_matrix(\n",
    "    './dataset/glove/glove.6B.100d.txt', \n",
    "    tokenizer.word_index, embedding_dim)\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the directory ckpt if it does not exist.\n",
    "#The ckpt directory is used to store the partially trained model\n",
    "import os\n",
    "checkpoint_dir = './ckpt'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + '/' + name\n",
    "                   for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print('Restoring from', latest_checkpoint)\n",
    "        return tf.keras.models.load_model(latest_checkpoint)\n",
    "    \n",
    "    #create a new model\n",
    "    print('Creating a new model')\n",
    "    return make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "def make_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(vocab_size, embedding_dim, \n",
    "                           weights=[embedding_matrix], \n",
    "                           input_length=max_length-1, \n",
    "                           trainable=True))\n",
    "    model.add(layers.LSTM(50, return_sequences=True))  \n",
    "    model.add(layers.LSTM(50))\n",
    "    model.add(layers.Dense(vocab_size, activation='softmax'))\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 15, 100)           263800    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 15, 50)            30200     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2638)              134538    \n",
      "=================================================================\n",
      "Total params: 448,738\n",
      "Trainable params: 448,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "\n",
    "model = make_or_restore_model()\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=5, monitor='accuracy')\n",
    "\n",
    "    # This callback checkpoint saves a SavedModel every epoch.\n",
    "    # We include the epoch and accuracy in the file name.\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + '/weights-improvement-{epoch:02d}-{accuracy:.2f}.hdf5', \n",
    "        monitor='accuracy',verbose=1,\n",
    "        save_best_only=False, mode = 'max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 6.1053 - accuracy: 0.0591\n",
      "Epoch 00001: saving model to ./ckpt\\weights-improvement-01-0.06.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 6.1041 - accuracy: 0.0592\n",
      "Epoch 2/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 5.7573 - accuracy: 0.0641\n",
      "Epoch 00002: saving model to ./ckpt\\weights-improvement-02-0.06.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 5.7585 - accuracy: 0.0640\n",
      "Epoch 3/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 5.5719 - accuracy: 0.0873\n",
      "Epoch 00003: saving model to ./ckpt\\weights-improvement-03-0.09.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 5.5703 - accuracy: 0.0873\n",
      "Epoch 4/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 5.3853 - accuracy: 0.1046\n",
      "Epoch 00004: saving model to ./ckpt\\weights-improvement-04-0.10.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 5.3856 - accuracy: 0.1046\n",
      "Epoch 5/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 5.2130 - accuracy: 0.1190\n",
      "Epoch 00005: saving model to ./ckpt\\weights-improvement-05-0.12.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 5.2130 - accuracy: 0.1190\n",
      "Epoch 6/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 5.0537 - accuracy: 0.1354\n",
      "Epoch 00006: saving model to ./ckpt\\weights-improvement-06-0.14.hdf5\n",
      "783/783 [==============================] - 20s 26ms/step - loss: 5.0538 - accuracy: 0.1355\n",
      "Epoch 7/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 4.9113 - accuracy: 0.1492\n",
      "Epoch 00007: saving model to ./ckpt\\weights-improvement-07-0.15.hdf5\n",
      "783/783 [==============================] - 21s 27ms/step - loss: 4.9125 - accuracy: 0.1491\n",
      "Epoch 8/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 4.7868 - accuracy: 0.1583\n",
      "Epoch 00008: saving model to ./ckpt\\weights-improvement-08-0.16.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 4.7873 - accuracy: 0.1583\n",
      "Epoch 9/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 4.6719 - accuracy: 0.1687\n",
      "Epoch 00009: saving model to ./ckpt\\weights-improvement-09-0.17.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 4.6719 - accuracy: 0.1687\n",
      "Epoch 10/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 4.5659 - accuracy: 0.1774\n",
      "Epoch 00010: saving model to ./ckpt\\weights-improvement-10-0.18.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 4.5659 - accuracy: 0.1774\n",
      "Epoch 11/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 4.4701 - accuracy: 0.1846\n",
      "Epoch 00011: saving model to ./ckpt\\weights-improvement-11-0.18.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 4.4700 - accuracy: 0.1846\n",
      "Epoch 12/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 4.3805 - accuracy: 0.1921\n",
      "Epoch 00012: saving model to ./ckpt\\weights-improvement-12-0.19.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 4.3806 - accuracy: 0.1921\n",
      "Epoch 13/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 4.2951 - accuracy: 0.1995\n",
      "Epoch 00013: saving model to ./ckpt\\weights-improvement-13-0.20.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 4.2951 - accuracy: 0.1995\n",
      "Epoch 14/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 4.2176 - accuracy: 0.2033\n",
      "Epoch 00014: saving model to ./ckpt\\weights-improvement-14-0.20.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 4.2171 - accuracy: 0.2034\n",
      "Epoch 15/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 4.1411 - accuracy: 0.2087\n",
      "Epoch 00015: saving model to ./ckpt\\weights-improvement-15-0.21.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 4.1411 - accuracy: 0.2087\n",
      "Epoch 16/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 4.0691 - accuracy: 0.2147\n",
      "Epoch 00016: saving model to ./ckpt\\weights-improvement-16-0.21.hdf5\n",
      "783/783 [==============================] - 21s 26ms/step - loss: 4.0690 - accuracy: 0.2148\n",
      "Epoch 17/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 4.0005 - accuracy: 0.2196\n",
      "Epoch 00017: saving model to ./ckpt\\weights-improvement-17-0.22.hdf5\n",
      "783/783 [==============================] - 20s 26ms/step - loss: 4.0019 - accuracy: 0.2194\n",
      "Epoch 18/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.9363 - accuracy: 0.2249\n",
      "Epoch 00018: saving model to ./ckpt\\weights-improvement-18-0.22.hdf5\n",
      "783/783 [==============================] - 21s 27ms/step - loss: 3.9363 - accuracy: 0.2249\n",
      "Epoch 19/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.8723 - accuracy: 0.2296\n",
      "Epoch 00019: saving model to ./ckpt\\weights-improvement-19-0.23.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 3.8723 - accuracy: 0.2296\n",
      "Epoch 20/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 3.8086 - accuracy: 0.2353\n",
      "Epoch 00020: saving model to ./ckpt\\weights-improvement-20-0.24.hdf5\n",
      "783/783 [==============================] - 22s 28ms/step - loss: 3.8087 - accuracy: 0.2354\n",
      "Epoch 21/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.7486 - accuracy: 0.2414\n",
      "Epoch 00021: saving model to ./ckpt\\weights-improvement-21-0.24.hdf5\n",
      "783/783 [==============================] - 21s 26ms/step - loss: 3.7486 - accuracy: 0.2414\n",
      "Epoch 22/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 3.6902 - accuracy: 0.2460 ETA: 0s - loss:\n",
      "Epoch 00022: saving model to ./ckpt\\weights-improvement-22-0.25.hdf5\n",
      "783/783 [==============================] - 21s 27ms/step - loss: 3.6902 - accuracy: 0.2460\n",
      "Epoch 23/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.6333 - accuracy: 0.2494\n",
      "Epoch 00023: saving model to ./ckpt\\weights-improvement-23-0.25.hdf5\n",
      "783/783 [==============================] - 23s 30ms/step - loss: 3.6333 - accuracy: 0.2494\n",
      "Epoch 24/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.5801 - accuracy: 0.2578 ETA: 1s\n",
      "Epoch 00024: saving model to ./ckpt\\weights-improvement-24-0.26.hdf5\n",
      "783/783 [==============================] - 22s 28ms/step - loss: 3.5801 - accuracy: 0.2578\n",
      "Epoch 25/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 3.5278 - accuracy: 0.2608\n",
      "Epoch 00025: saving model to ./ckpt\\weights-improvement-25-0.26.hdf5\n",
      "783/783 [==============================] - 21s 27ms/step - loss: 3.5280 - accuracy: 0.2607\n",
      "Epoch 26/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 3.4759 - accuracy: 0.2690\n",
      "Epoch 00026: saving model to ./ckpt\\weights-improvement-26-0.27.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 3.4748 - accuracy: 0.2692\n",
      "Epoch 27/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.4240 - accuracy: 0.2775\n",
      "Epoch 00027: saving model to ./ckpt\\weights-improvement-27-0.28.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 3.4240 - accuracy: 0.2775\n",
      "Epoch 28/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 3.3758 - accuracy: 0.2829\n",
      "Epoch 00028: saving model to ./ckpt\\weights-improvement-28-0.28.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 3.3755 - accuracy: 0.2830\n",
      "Epoch 29/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.3278 - accuracy: 0.2925\n",
      "Epoch 00029: saving model to ./ckpt\\weights-improvement-29-0.29.hdf5\n",
      "783/783 [==============================] - 21s 27ms/step - loss: 3.3278 - accuracy: 0.2925\n",
      "Epoch 30/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 3.2806 - accuracy: 0.2973\n",
      "Epoch 00030: saving model to ./ckpt\\weights-improvement-30-0.30.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 3.2802 - accuracy: 0.2974\n",
      "Epoch 31/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.2343 - accuracy: 0.3050\n",
      "Epoch 00031: saving model to ./ckpt\\weights-improvement-31-0.31.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 3.2343 - accuracy: 0.3050\n",
      "Epoch 32/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.1902 - accuracy: 0.3133\n",
      "Epoch 00032: saving model to ./ckpt\\weights-improvement-32-0.31.hdf5\n",
      "783/783 [==============================] - 22s 28ms/step - loss: 3.1902 - accuracy: 0.3133\n",
      "Epoch 33/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 3.1448 - accuracy: 0.3205\n",
      "Epoch 00033: saving model to ./ckpt\\weights-improvement-33-0.32.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 3.1449 - accuracy: 0.3208\n",
      "Epoch 34/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.1015 - accuracy: 0.3288\n",
      "Epoch 00034: saving model to ./ckpt\\weights-improvement-34-0.33.hdf5\n",
      "783/783 [==============================] - 23s 29ms/step - loss: 3.1015 - accuracy: 0.3288\n",
      "Epoch 35/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 3.0603 - accuracy: 0.3340\n",
      "Epoch 00035: saving model to ./ckpt\\weights-improvement-35-0.33.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 3.0603 - accuracy: 0.3340\n",
      "Epoch 36/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 3.0160 - accuracy: 0.3423\n",
      "Epoch 00036: saving model to ./ckpt\\weights-improvement-36-0.34.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 3.0166 - accuracy: 0.3422\n",
      "Epoch 37/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.9767 - accuracy: 0.3479\n",
      "Epoch 00037: saving model to ./ckpt\\weights-improvement-37-0.35.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 2.9757 - accuracy: 0.3483\n",
      "Epoch 38/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 2.9355 - accuracy: 0.3578\n",
      "Epoch 00038: saving model to ./ckpt\\weights-improvement-38-0.36.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 2.9355 - accuracy: 0.3578\n",
      "Epoch 39/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.8955 - accuracy: 0.3645\n",
      "Epoch 00039: saving model to ./ckpt\\weights-improvement-39-0.36.hdf5\n",
      "783/783 [==============================] - 20s 26ms/step - loss: 2.8953 - accuracy: 0.3646\n",
      "Epoch 40/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 2.8571 - accuracy: 0.3709\n",
      "Epoch 00040: saving model to ./ckpt\\weights-improvement-40-0.37.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 2.8571 - accuracy: 0.3709\n",
      "Epoch 41/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 2.8182 - accuracy: 0.3777\n",
      "Epoch 00041: saving model to ./ckpt\\weights-improvement-41-0.38.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 2.8182 - accuracy: 0.3777\n",
      "Epoch 42/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 2.7783 - accuracy: 0.3841\n",
      "Epoch 00042: saving model to ./ckpt\\weights-improvement-42-0.38.hdf5\n",
      "783/783 [==============================] - 24s 30ms/step - loss: 2.7786 - accuracy: 0.3840\n",
      "Epoch 43/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.7440 - accuracy: 0.3904\n",
      "Epoch 00043: saving model to ./ckpt\\weights-improvement-43-0.39.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 2.7440 - accuracy: 0.3904\n",
      "Epoch 44/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 2.7071 - accuracy: 0.3986\n",
      "Epoch 00044: saving model to ./ckpt\\weights-improvement-44-0.40.hdf5\n",
      "783/783 [==============================] - 21s 26ms/step - loss: 2.7076 - accuracy: 0.3985\n",
      "Epoch 45/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 2.6704 - accuracy: 0.4053\n",
      "Epoch 00045: saving model to ./ckpt\\weights-improvement-45-0.41.hdf5\n",
      "783/783 [==============================] - 23s 29ms/step - loss: 2.6704 - accuracy: 0.4053\n",
      "Epoch 46/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 2.6348 - accuracy: 0.4122\n",
      "Epoch 00046: saving model to ./ckpt\\weights-improvement-46-0.41.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 2.6348 - accuracy: 0.4122\n",
      "Epoch 47/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 2.5987 - accuracy: 0.4202\n",
      "Epoch 00047: saving model to ./ckpt\\weights-improvement-47-0.42.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 2.5980 - accuracy: 0.4204\n",
      "Epoch 48/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.5639 - accuracy: 0.4278\n",
      "Epoch 00048: saving model to ./ckpt\\weights-improvement-48-0.43.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 2.5637 - accuracy: 0.4280\n",
      "Epoch 49/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 2.5307 - accuracy: 0.4344\n",
      "Epoch 00049: saving model to ./ckpt\\weights-improvement-49-0.43.hdf5\n",
      "783/783 [==============================] - 22s 29ms/step - loss: 2.5307 - accuracy: 0.4344\n",
      "Epoch 50/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.4972 - accuracy: 0.4392\n",
      "Epoch 00050: saving model to ./ckpt\\weights-improvement-50-0.44.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 2.4974 - accuracy: 0.4391\n",
      "Epoch 51/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.4618 - accuracy: 0.4477\n",
      "Epoch 00051: saving model to ./ckpt\\weights-improvement-51-0.45.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 2.4623 - accuracy: 0.4476\n",
      "Epoch 52/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.4317 - accuracy: 0.4539\n",
      "Epoch 00052: saving model to ./ckpt\\weights-improvement-52-0.45.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 2.4324 - accuracy: 0.4536\n",
      "Epoch 53/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 2.4002 - accuracy: 0.4593 E\n",
      "Epoch 00053: saving model to ./ckpt\\weights-improvement-53-0.46.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 2.4007 - accuracy: 0.4593\n",
      "Epoch 54/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 2.3677 - accuracy: 0.4678\n",
      "Epoch 00054: saving model to ./ckpt\\weights-improvement-54-0.47.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.3679 - accuracy: 0.4678\n",
      "Epoch 55/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.3359 - accuracy: 0.4755\n",
      "Epoch 00055: saving model to ./ckpt\\weights-improvement-55-0.48.hdf5\n",
      "783/783 [==============================] - 12s 16ms/step - loss: 2.3353 - accuracy: 0.4757\n",
      "Epoch 56/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 2.3044 - accuracy: 0.4816\n",
      "Epoch 00056: saving model to ./ckpt\\weights-improvement-56-0.48.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.3038 - accuracy: 0.4818\n",
      "Epoch 57/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 2.2755 - accuracy: 0.4886\n",
      "Epoch 00057: saving model to ./ckpt\\weights-improvement-57-0.49.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.2755 - accuracy: 0.4886\n",
      "Epoch 58/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.2435 - accuracy: 0.4950\n",
      "Epoch 00058: saving model to ./ckpt\\weights-improvement-58-0.50.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.2427 - accuracy: 0.4953\n",
      "Epoch 59/500\n",
      "780/783 [============================>.] - ETA: 0s - loss: 2.2158 - accuracy: 0.5000\n",
      "Epoch 00059: saving model to ./ckpt\\weights-improvement-59-0.50.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.2157 - accuracy: 0.5002\n",
      "Epoch 60/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.1882 - accuracy: 0.5097\n",
      "Epoch 00060: saving model to ./ckpt\\weights-improvement-60-0.51.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.1884 - accuracy: 0.5096\n",
      "Epoch 61/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 2.1589 - accuracy: 0.5122\n",
      "Epoch 00061: saving model to ./ckpt\\weights-improvement-61-0.51.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.1587 - accuracy: 0.5123\n",
      "Epoch 62/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 2.1296 - accuracy: 0.5199\n",
      "Epoch 00062: saving model to ./ckpt\\weights-improvement-62-0.52.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.1296 - accuracy: 0.5199\n",
      "Epoch 63/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.1036 - accuracy: 0.5237\n",
      "Epoch 00063: saving model to ./ckpt\\weights-improvement-63-0.52.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.1039 - accuracy: 0.5236\n",
      "Epoch 64/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 2.0744 - accuracy: 0.5305\n",
      "Epoch 00064: saving model to ./ckpt\\weights-improvement-64-0.53.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.0744 - accuracy: 0.5305\n",
      "Epoch 65/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 2.0459 - accuracy: 0.5352 ETA: 0s - loss: 2.0447 - accuracy: 0.\n",
      "Epoch 00065: saving model to ./ckpt\\weights-improvement-65-0.54.hdf5\n",
      "783/783 [==============================] - 13s 17ms/step - loss: 2.0464 - accuracy: 0.5351\n",
      "Epoch 66/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 2.0230 - accuracy: 0.5394\n",
      "Epoch 00066: saving model to ./ckpt\\weights-improvement-66-0.54.hdf5\n",
      "783/783 [==============================] - 14s 17ms/step - loss: 2.0231 - accuracy: 0.5395\n",
      "Epoch 67/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.9969 - accuracy: 0.5485\n",
      "Epoch 00067: saving model to ./ckpt\\weights-improvement-67-0.55.hdf5\n",
      "783/783 [==============================] - 14s 17ms/step - loss: 1.9969 - accuracy: 0.5485\n",
      "Epoch 68/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.9703 - accuracy: 0.5520\n",
      "Epoch 00068: saving model to ./ckpt\\weights-improvement-68-0.55.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.9703 - accuracy: 0.5520\n",
      "Epoch 69/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.9423 - accuracy: 0.5607\n",
      "Epoch 00069: saving model to ./ckpt\\weights-improvement-69-0.56.hdf5\n",
      "783/783 [==============================] - 14s 17ms/step - loss: 1.9428 - accuracy: 0.5606\n",
      "Epoch 70/500\n",
      "780/783 [============================>.] - ETA: 0s - loss: 1.9201 - accuracy: 0.5639\n",
      "Epoch 00070: saving model to ./ckpt\\weights-improvement-70-0.56.hdf5\n",
      "783/783 [==============================] - 14s 17ms/step - loss: 1.9207 - accuracy: 0.5641\n",
      "Epoch 71/500\n",
      "780/783 [============================>.] - ETA: 0s - loss: 1.8940 - accuracy: 0.5684\n",
      "Epoch 00071: saving model to ./ckpt\\weights-improvement-71-0.57.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.8934 - accuracy: 0.5686\n",
      "Epoch 72/500\n",
      "780/783 [============================>.] - ETA: 0s - loss: 1.8696 - accuracy: 0.5775\n",
      "Epoch 00072: saving model to ./ckpt\\weights-improvement-72-0.58.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.8699 - accuracy: 0.5773\n",
      "Epoch 73/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.8469 - accuracy: 0.5819\n",
      "Epoch 00073: saving model to ./ckpt\\weights-improvement-73-0.58.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.8471 - accuracy: 0.5819\n",
      "Epoch 74/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.8245 - accuracy: 0.5852\n",
      "Epoch 00074: saving model to ./ckpt\\weights-improvement-74-0.58.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.8251 - accuracy: 0.5850\n",
      "Epoch 75/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.8024 - accuracy: 0.5899\n",
      "Epoch 00075: saving model to ./ckpt\\weights-improvement-75-0.59.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.8024 - accuracy: 0.5899\n",
      "Epoch 76/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.7766 - accuracy: 0.5952\n",
      "Epoch 00076: saving model to ./ckpt\\weights-improvement-76-0.60.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.7765 - accuracy: 0.5952\n",
      "Epoch 77/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.7553 - accuracy: 0.5984\n",
      "Epoch 00077: saving model to ./ckpt\\weights-improvement-77-0.60.hdf5\n",
      "783/783 [==============================] - 16s 20ms/step - loss: 1.7553 - accuracy: 0.5984\n",
      "Epoch 78/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.7342 - accuracy: 0.6076\n",
      "Epoch 00078: saving model to ./ckpt\\weights-improvement-78-0.61.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.7346 - accuracy: 0.6074\n",
      "Epoch 79/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.7078 - accuracy: 0.6127\n",
      "Epoch 00079: saving model to ./ckpt\\weights-improvement-79-0.61.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.7078 - accuracy: 0.6127\n",
      "Epoch 80/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.6859 - accuracy: 0.6161\n",
      "Epoch 00080: saving model to ./ckpt\\weights-improvement-80-0.62.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.6859 - accuracy: 0.6161\n",
      "Epoch 81/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.6668 - accuracy: 0.6204\n",
      "Epoch 00081: saving model to ./ckpt\\weights-improvement-81-0.62.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.6659 - accuracy: 0.6207\n",
      "Epoch 82/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.6487 - accuracy: 0.6267\n",
      "Epoch 00082: saving model to ./ckpt\\weights-improvement-82-0.63.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.6489 - accuracy: 0.6265\n",
      "Epoch 83/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.6257 - accuracy: 0.6293\n",
      "Epoch 00083: saving model to ./ckpt\\weights-improvement-83-0.63.hdf5\n",
      "783/783 [==============================] - 14s 18ms/step - loss: 1.6258 - accuracy: 0.6292\n",
      "Epoch 84/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.6062 - accuracy: 0.6350\n",
      "Epoch 00084: saving model to ./ckpt\\weights-improvement-84-0.64.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.6062 - accuracy: 0.6352\n",
      "Epoch 85/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.5875 - accuracy: 0.6385\n",
      "Epoch 00085: saving model to ./ckpt\\weights-improvement-85-0.64.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.5876 - accuracy: 0.6384\n",
      "Epoch 86/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.5664 - accuracy: 0.6414\n",
      "Epoch 00086: saving model to ./ckpt\\weights-improvement-86-0.64.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.5663 - accuracy: 0.6413\n",
      "Epoch 87/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.5465 - accuracy: 0.6486\n",
      "Epoch 00087: saving model to ./ckpt\\weights-improvement-87-0.65.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.5463 - accuracy: 0.6485\n",
      "Epoch 88/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.5289 - accuracy: 0.6514\n",
      "Epoch 00088: saving model to ./ckpt\\weights-improvement-88-0.65.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.5290 - accuracy: 0.6514\n",
      "Epoch 89/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.5100 - accuracy: 0.6573\n",
      "Epoch 00089: saving model to ./ckpt\\weights-improvement-89-0.66.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.5107 - accuracy: 0.6572\n",
      "Epoch 90/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.4916 - accuracy: 0.6607\n",
      "Epoch 00090: saving model to ./ckpt\\weights-improvement-90-0.66.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.4919 - accuracy: 0.6606\n",
      "Epoch 91/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.4740 - accuracy: 0.6657\n",
      "Epoch 00091: saving model to ./ckpt\\weights-improvement-91-0.67.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 1.4740 - accuracy: 0.6657\n",
      "Epoch 92/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.4585 - accuracy: 0.6703\n",
      "Epoch 00092: saving model to ./ckpt\\weights-improvement-92-0.67.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.4582 - accuracy: 0.6704\n",
      "Epoch 93/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.4392 - accuracy: 0.6709\n",
      "Epoch 00093: saving model to ./ckpt\\weights-improvement-93-0.67.hdf5\n",
      "783/783 [==============================] - 15s 20ms/step - loss: 1.4392 - accuracy: 0.6709\n",
      "Epoch 94/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.4225 - accuracy: 0.6751\n",
      "Epoch 00094: saving model to ./ckpt\\weights-improvement-94-0.68.hdf5\n",
      "783/783 [==============================] - 15s 19ms/step - loss: 1.4224 - accuracy: 0.6751\n",
      "Epoch 95/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.4044 - accuracy: 0.6817\n",
      "Epoch 00095: saving model to ./ckpt\\weights-improvement-95-0.68.hdf5\n",
      "783/783 [==============================] - 16s 20ms/step - loss: 1.4038 - accuracy: 0.6819\n",
      "Epoch 96/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.3895 - accuracy: 0.6840\n",
      "Epoch 00096: saving model to ./ckpt\\weights-improvement-96-0.68.hdf5\n",
      "783/783 [==============================] - 15s 20ms/step - loss: 1.3890 - accuracy: 0.6840\n",
      "Epoch 97/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.3720 - accuracy: 0.6880\n",
      "Epoch 00097: saving model to ./ckpt\\weights-improvement-97-0.69.hdf5\n",
      "783/783 [==============================] - 15s 20ms/step - loss: 1.3723 - accuracy: 0.6879\n",
      "Epoch 98/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.3586 - accuracy: 0.6875\n",
      "Epoch 00098: saving model to ./ckpt\\weights-improvement-98-0.69.hdf5\n",
      "783/783 [==============================] - 15s 20ms/step - loss: 1.3583 - accuracy: 0.6876\n",
      "Epoch 99/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.3408 - accuracy: 0.6928\n",
      "Epoch 00099: saving model to ./ckpt\\weights-improvement-99-0.69.hdf5\n",
      "783/783 [==============================] - 16s 20ms/step - loss: 1.3408 - accuracy: 0.6928\n",
      "Epoch 100/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.3261 - accuracy: 0.6947\n",
      "Epoch 00100: saving model to ./ckpt\\weights-improvement-100-0.69.hdf5\n",
      "783/783 [==============================] - 16s 20ms/step - loss: 1.3257 - accuracy: 0.6950\n",
      "Epoch 101/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.3108 - accuracy: 0.7000\n",
      "Epoch 00101: saving model to ./ckpt\\weights-improvement-101-0.70.hdf5\n",
      "783/783 [==============================] - 16s 20ms/step - loss: 1.3108 - accuracy: 0.7000\n",
      "Epoch 102/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.2964 - accuracy: 0.7037\n",
      "Epoch 00102: saving model to ./ckpt\\weights-improvement-102-0.70.hdf5\n",
      "783/783 [==============================] - 16s 20ms/step - loss: 1.2964 - accuracy: 0.7037\n",
      "Epoch 103/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.2803 - accuracy: 0.7078\n",
      "Epoch 00103: saving model to ./ckpt\\weights-improvement-103-0.71.hdf5\n",
      "783/783 [==============================] - 18s 22ms/step - loss: 1.2802 - accuracy: 0.7078\n",
      "Epoch 104/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.2708 - accuracy: 0.7102\n",
      "Epoch 00104: saving model to ./ckpt\\weights-improvement-104-0.71.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 1.2708 - accuracy: 0.7102\n",
      "Epoch 105/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.2528 - accuracy: 0.7142\n",
      "Epoch 00105: saving model to ./ckpt\\weights-improvement-105-0.71.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 1.2528 - accuracy: 0.7142\n",
      "Epoch 106/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.2377 - accuracy: 0.7166\n",
      "Epoch 00106: saving model to ./ckpt\\weights-improvement-106-0.72.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 1.2378 - accuracy: 0.7165\n",
      "Epoch 107/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.2252 - accuracy: 0.7185\n",
      "Epoch 00107: saving model to ./ckpt\\weights-improvement-107-0.72.hdf5\n",
      "783/783 [==============================] - 18s 22ms/step - loss: 1.2245 - accuracy: 0.7188\n",
      "Epoch 108/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.2169 - accuracy: 0.7226\n",
      "Epoch 00108: saving model to ./ckpt\\weights-improvement-108-0.72.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 1.2169 - accuracy: 0.7225\n",
      "Epoch 109/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.1996 - accuracy: 0.7249\n",
      "Epoch 00109: saving model to ./ckpt\\weights-improvement-109-0.72.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 1.1996 - accuracy: 0.7249\n",
      "Epoch 110/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.1843 - accuracy: 0.7307\n",
      "Epoch 00110: saving model to ./ckpt\\weights-improvement-110-0.73.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 1.1843 - accuracy: 0.7307\n",
      "Epoch 111/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.1785 - accuracy: 0.7315\n",
      "Epoch 00111: saving model to ./ckpt\\weights-improvement-111-0.73.hdf5\n",
      "783/783 [==============================] - 20s 26ms/step - loss: 1.1782 - accuracy: 0.7316\n",
      "Epoch 112/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.1617 - accuracy: 0.7334\n",
      "Epoch 00112: saving model to ./ckpt\\weights-improvement-112-0.73.hdf5\n",
      "783/783 [==============================] - 21s 27ms/step - loss: 1.1617 - accuracy: 0.7334\n",
      "Epoch 113/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.1507 - accuracy: 0.7365\n",
      "Epoch 00113: saving model to ./ckpt\\weights-improvement-113-0.74.hdf5\n",
      "783/783 [==============================] - 23s 30ms/step - loss: 1.1505 - accuracy: 0.7366\n",
      "Epoch 114/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.1372 - accuracy: 0.7390 ETA: 0s - loss: 1.1371 - accuracy: 0.73\n",
      "Epoch 00114: saving model to ./ckpt\\weights-improvement-114-0.74.hdf5\n",
      "783/783 [==============================] - 23s 30ms/step - loss: 1.1372 - accuracy: 0.7390\n",
      "Epoch 115/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.1228 - accuracy: 0.7414 ETA: 0s - l\n",
      "Epoch 00115: saving model to ./ckpt\\weights-improvement-115-0.74.hdf5\n",
      "783/783 [==============================] - 22s 28ms/step - loss: 1.1230 - accuracy: 0.7414\n",
      "Epoch 116/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.1137 - accuracy: 0.7445\n",
      "Epoch 00116: saving model to ./ckpt\\weights-improvement-116-0.74.hdf5\n",
      "783/783 [==============================] - 21s 27ms/step - loss: 1.1143 - accuracy: 0.7444\n",
      "Epoch 117/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.1009 - accuracy: 0.7472\n",
      "Epoch 00117: saving model to ./ckpt\\weights-improvement-117-0.75.hdf5\n",
      "783/783 [==============================] - 20s 26ms/step - loss: 1.1009 - accuracy: 0.7471\n",
      "Epoch 118/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.0953 - accuracy: 0.7480\n",
      "Epoch 00118: saving model to ./ckpt\\weights-improvement-118-0.75.hdf5\n",
      "783/783 [==============================] - 22s 28ms/step - loss: 1.0956 - accuracy: 0.7479\n",
      "Epoch 119/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.0894 - accuracy: 0.7485\n",
      "Epoch 00119: saving model to ./ckpt\\weights-improvement-119-0.75.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 1.0900 - accuracy: 0.7484\n",
      "Epoch 120/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.0674 - accuracy: 0.7552 ETA: 0s - loss: 1.0685 - accuracy: 0.\n",
      "Epoch 00120: saving model to ./ckpt\\weights-improvement-120-0.76.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 1.0675 - accuracy: 0.7552\n",
      "Epoch 121/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.0563 - accuracy: 0.7566\n",
      "Epoch 00121: saving model to ./ckpt\\weights-improvement-121-0.76.hdf5\n",
      "783/783 [==============================] - 21s 26ms/step - loss: 1.0567 - accuracy: 0.7565\n",
      "Epoch 122/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.0511 - accuracy: 0.7584\n",
      "Epoch 00122: saving model to ./ckpt\\weights-improvement-122-0.76.hdf5\n",
      "783/783 [==============================] - 25s 31ms/step - loss: 1.0511 - accuracy: 0.7584\n",
      "Epoch 123/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 1.0413 - accuracy: 0.7602\n",
      "Epoch 00123: saving model to ./ckpt\\weights-improvement-123-0.76.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 1.0411 - accuracy: 0.7603\n",
      "Epoch 124/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 1.0322 - accuracy: 0.7611\n",
      "Epoch 00124: saving model to ./ckpt\\weights-improvement-124-0.76.hdf5\n",
      "783/783 [==============================] - 20s 26ms/step - loss: 1.0318 - accuracy: 0.7611\n",
      "Epoch 125/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.0184 - accuracy: 0.7671\n",
      "Epoch 00125: saving model to ./ckpt\\weights-improvement-125-0.77.hdf5\n",
      "783/783 [==============================] - 21s 26ms/step - loss: 1.0184 - accuracy: 0.7671\n",
      "Epoch 126/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 1.0097 - accuracy: 0.7679\n",
      "Epoch 00126: saving model to ./ckpt\\weights-improvement-126-0.77.hdf5\n",
      "783/783 [==============================] - 17s 22ms/step - loss: 1.0097 - accuracy: 0.7679\n",
      "Epoch 127/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.9972 - accuracy: 0.7710\n",
      "Epoch 00127: saving model to ./ckpt\\weights-improvement-127-0.77.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 0.9972 - accuracy: 0.7710\n",
      "Epoch 128/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.9929 - accuracy: 0.7696\n",
      "Epoch 00128: saving model to ./ckpt\\weights-improvement-128-0.77.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 0.9929 - accuracy: 0.7696\n",
      "Epoch 129/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.9801 - accuracy: 0.7747\n",
      "Epoch 00129: saving model to ./ckpt\\weights-improvement-129-0.77.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.9801 - accuracy: 0.7747\n",
      "Epoch 130/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.9680 - accuracy: 0.7779\n",
      "Epoch 00130: saving model to ./ckpt\\weights-improvement-130-0.78.hdf5\n",
      "783/783 [==============================] - 16s 20ms/step - loss: 0.9687 - accuracy: 0.7777\n",
      "Epoch 131/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.9627 - accuracy: 0.7782\n",
      "Epoch 00131: saving model to ./ckpt\\weights-improvement-131-0.78.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.9627 - accuracy: 0.7782\n",
      "Epoch 132/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.9568 - accuracy: 0.7783\n",
      "Epoch 00132: saving model to ./ckpt\\weights-improvement-132-0.78.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 0.9568 - accuracy: 0.7784\n",
      "Epoch 133/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.9448 - accuracy: 0.7834\n",
      "Epoch 00133: saving model to ./ckpt\\weights-improvement-133-0.78.hdf5\n",
      "783/783 [==============================] - 17s 22ms/step - loss: 0.9451 - accuracy: 0.7833\n",
      "Epoch 134/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.9363 - accuracy: 0.7846\n",
      "Epoch 00134: saving model to ./ckpt\\weights-improvement-134-0.78.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.9373 - accuracy: 0.7844\n",
      "Epoch 135/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.9273 - accuracy: 0.7884\n",
      "Epoch 00135: saving model to ./ckpt\\weights-improvement-135-0.79.hdf5\n",
      "783/783 [==============================] - 17s 22ms/step - loss: 0.9272 - accuracy: 0.7885\n",
      "Epoch 136/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.9197 - accuracy: 0.7895\n",
      "Epoch 00136: saving model to ./ckpt\\weights-improvement-136-0.79.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.9197 - accuracy: 0.7895\n",
      "Epoch 137/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.9084 - accuracy: 0.7894\n",
      "Epoch 00137: saving model to ./ckpt\\weights-improvement-137-0.79.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.9088 - accuracy: 0.7893\n",
      "Epoch 138/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.9003 - accuracy: 0.7947\n",
      "Epoch 00138: saving model to ./ckpt\\weights-improvement-138-0.79.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.9003 - accuracy: 0.7947\n",
      "Epoch 139/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.8977 - accuracy: 0.7945\n",
      "Epoch 00139: saving model to ./ckpt\\weights-improvement-139-0.79.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 0.8977 - accuracy: 0.7945\n",
      "Epoch 140/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.8907 - accuracy: 0.7938\n",
      "Epoch 00140: saving model to ./ckpt\\weights-improvement-140-0.79.hdf5\n",
      "783/783 [==============================] - 16s 20ms/step - loss: 0.8907 - accuracy: 0.7938\n",
      "Epoch 141/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.8799 - accuracy: 0.7984\n",
      "Epoch 00141: saving model to ./ckpt\\weights-improvement-141-0.80.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.8799 - accuracy: 0.7984\n",
      "Epoch 142/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.8705 - accuracy: 0.7981\n",
      "Epoch 00142: saving model to ./ckpt\\weights-improvement-142-0.80.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.8715 - accuracy: 0.7980\n",
      "Epoch 143/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.8640 - accuracy: 0.8004\n",
      "Epoch 00143: saving model to ./ckpt\\weights-improvement-143-0.80.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 0.8643 - accuracy: 0.8004\n",
      "Epoch 144/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.8671 - accuracy: 0.7991\n",
      "Epoch 00144: saving model to ./ckpt\\weights-improvement-144-0.80.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.8673 - accuracy: 0.7991\n",
      "Epoch 145/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.8527 - accuracy: 0.8027\n",
      "Epoch 00145: saving model to ./ckpt\\weights-improvement-145-0.80.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.8522 - accuracy: 0.8029\n",
      "Epoch 146/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.8458 - accuracy: 0.8056\n",
      "Epoch 00146: saving model to ./ckpt\\weights-improvement-146-0.81.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 0.8458 - accuracy: 0.8056\n",
      "Epoch 147/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.8357 - accuracy: 0.8079 ETA: 0s - loss: 0.8340 - ac\n",
      "Epoch 00147: saving model to ./ckpt\\weights-improvement-147-0.81.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 0.8357 - accuracy: 0.8079\n",
      "Epoch 148/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.8321 - accuracy: 0.8076\n",
      "Epoch 00148: saving model to ./ckpt\\weights-improvement-148-0.81.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.8319 - accuracy: 0.8077\n",
      "Epoch 149/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.8230 - accuracy: 0.8089\n",
      "Epoch 00149: saving model to ./ckpt\\weights-improvement-149-0.81.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.8230 - accuracy: 0.8088\n",
      "Epoch 150/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.8186 - accuracy: 0.8131\n",
      "Epoch 00150: saving model to ./ckpt\\weights-improvement-150-0.81.hdf5\n",
      "783/783 [==============================] - 17s 22ms/step - loss: 0.8186 - accuracy: 0.8130\n",
      "Epoch 151/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.8127 - accuracy: 0.8120\n",
      "Epoch 00151: saving model to ./ckpt\\weights-improvement-151-0.81.hdf5\n",
      "783/783 [==============================] - 16s 20ms/step - loss: 0.8122 - accuracy: 0.8120\n",
      "Epoch 152/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.8028 - accuracy: 0.8138\n",
      "Epoch 00152: saving model to ./ckpt\\weights-improvement-152-0.81.hdf5\n",
      "783/783 [==============================] - 15s 20ms/step - loss: 0.8028 - accuracy: 0.8138\n",
      "Epoch 153/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.8087 - accuracy: 0.8121\n",
      "Epoch 00153: saving model to ./ckpt\\weights-improvement-153-0.81.hdf5\n",
      "783/783 [==============================] - 17s 22ms/step - loss: 0.8090 - accuracy: 0.8120\n",
      "Epoch 154/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.7904 - accuracy: 0.8186\n",
      "Epoch 00154: saving model to ./ckpt\\weights-improvement-154-0.82.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.7904 - accuracy: 0.8186\n",
      "Epoch 155/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.7876 - accuracy: 0.8164\n",
      "Epoch 00155: saving model to ./ckpt\\weights-improvement-155-0.82.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 0.7873 - accuracy: 0.8165\n",
      "Epoch 156/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.7758 - accuracy: 0.8196\n",
      "Epoch 00156: saving model to ./ckpt\\weights-improvement-156-0.82.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.7758 - accuracy: 0.8196\n",
      "Epoch 157/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.7645 - accuracy: 0.8230\n",
      "Epoch 00157: saving model to ./ckpt\\weights-improvement-157-0.82.hdf5\n",
      "783/783 [==============================] - 17s 22ms/step - loss: 0.7645 - accuracy: 0.8230\n",
      "Epoch 158/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.7752 - accuracy: 0.8205\n",
      "Epoch 00158: saving model to ./ckpt\\weights-improvement-158-0.82.hdf5\n",
      "783/783 [==============================] - 16s 21ms/step - loss: 0.7751 - accuracy: 0.8203\n",
      "Epoch 159/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.7744 - accuracy: 0.8202\n",
      "Epoch 00159: saving model to ./ckpt\\weights-improvement-159-0.82.hdf5\n",
      "783/783 [==============================] - 17s 21ms/step - loss: 0.7749 - accuracy: 0.8202\n",
      "Epoch 160/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.7526 - accuracy: 0.8263\n",
      "Epoch 00160: saving model to ./ckpt\\weights-improvement-160-0.83.hdf5\n",
      "783/783 [==============================] - 21s 26ms/step - loss: 0.7526 - accuracy: 0.8263\n",
      "Epoch 161/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.7514 - accuracy: 0.8249\n",
      "Epoch 00161: saving model to ./ckpt\\weights-improvement-161-0.82.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 0.7514 - accuracy: 0.8249\n",
      "Epoch 162/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.7415 - accuracy: 0.8279\n",
      "Epoch 00162: saving model to ./ckpt\\weights-improvement-162-0.83.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 0.7414 - accuracy: 0.8280\n",
      "Epoch 163/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.7497 - accuracy: 0.8246\n",
      "Epoch 00163: saving model to ./ckpt\\weights-improvement-163-0.82.hdf5\n",
      "783/783 [==============================] - 17s 22ms/step - loss: 0.7497 - accuracy: 0.8246\n",
      "Epoch 164/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.7362 - accuracy: 0.8295\n",
      "Epoch 00164: saving model to ./ckpt\\weights-improvement-164-0.83.hdf5\n",
      "783/783 [==============================] - 17s 22ms/step - loss: 0.7359 - accuracy: 0.8295\n",
      "Epoch 165/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.7322 - accuracy: 0.8282\n",
      "Epoch 00165: saving model to ./ckpt\\weights-improvement-165-0.83.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 0.7326 - accuracy: 0.8281\n",
      "Epoch 166/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.7218 - accuracy: 0.8311\n",
      "Epoch 00166: saving model to ./ckpt\\weights-improvement-166-0.83.hdf5\n",
      "783/783 [==============================] - 18s 22ms/step - loss: 0.7218 - accuracy: 0.8311\n",
      "Epoch 167/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.7146 - accuracy: 0.8342\n",
      "Epoch 00167: saving model to ./ckpt\\weights-improvement-167-0.83.hdf5\n",
      "783/783 [==============================] - 17s 22ms/step - loss: 0.7147 - accuracy: 0.8342\n",
      "Epoch 168/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.7255 - accuracy: 0.8304\n",
      "Epoch 00168: saving model to ./ckpt\\weights-improvement-168-0.83.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.7258 - accuracy: 0.8304\n",
      "Epoch 169/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.7145 - accuracy: 0.8335\n",
      "Epoch 00169: saving model to ./ckpt\\weights-improvement-169-0.83.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.7145 - accuracy: 0.8335\n",
      "Epoch 170/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6986 - accuracy: 0.8358\n",
      "Epoch 00170: saving model to ./ckpt\\weights-improvement-170-0.84.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 0.6986 - accuracy: 0.8358\n",
      "Epoch 171/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.7014 - accuracy: 0.8348\n",
      "Epoch 00171: saving model to ./ckpt\\weights-improvement-171-0.83.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 0.7018 - accuracy: 0.8347\n",
      "Epoch 172/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6982 - accuracy: 0.8365\n",
      "Epoch 00172: saving model to ./ckpt\\weights-improvement-172-0.84.hdf5\n",
      "783/783 [==============================] - 18s 23ms/step - loss: 0.6982 - accuracy: 0.8365\n",
      "Epoch 173/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6933 - accuracy: 0.8351\n",
      "Epoch 00173: saving model to ./ckpt\\weights-improvement-173-0.84.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6933 - accuracy: 0.8351\n",
      "Epoch 174/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.7001 - accuracy: 0.8344\n",
      "Epoch 00174: saving model to ./ckpt\\weights-improvement-174-0.83.hdf5\n",
      "783/783 [==============================] - 22s 28ms/step - loss: 0.6999 - accuracy: 0.8344\n",
      "Epoch 175/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.6860 - accuracy: 0.8381\n",
      "Epoch 00175: saving model to ./ckpt\\weights-improvement-175-0.84.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6865 - accuracy: 0.8380\n",
      "Epoch 176/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6687 - accuracy: 0.8427\n",
      "Epoch 00176: saving model to ./ckpt\\weights-improvement-176-0.84.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 0.6687 - accuracy: 0.8427\n",
      "Epoch 177/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.6845 - accuracy: 0.8397\n",
      "Epoch 00177: saving model to ./ckpt\\weights-improvement-177-0.84.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 0.6843 - accuracy: 0.8397\n",
      "Epoch 178/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6841 - accuracy: 0.8380\n",
      "Epoch 00178: saving model to ./ckpt\\weights-improvement-178-0.84.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6841 - accuracy: 0.8380\n",
      "Epoch 179/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.8406\n",
      "Epoch 00179: saving model to ./ckpt\\weights-improvement-179-0.84.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6720 - accuracy: 0.8406\n",
      "Epoch 180/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.6500 - accuracy: 0.8474\n",
      "Epoch 00180: saving model to ./ckpt\\weights-improvement-180-0.85.hdf5\n",
      "783/783 [==============================] - 20s 26ms/step - loss: 0.6500 - accuracy: 0.8474\n",
      "Epoch 181/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.8482\n",
      "Epoch 00181: saving model to ./ckpt\\weights-improvement-181-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6533 - accuracy: 0.8482\n",
      "Epoch 182/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.6572 - accuracy: 0.8450\n",
      "Epoch 00182: saving model to ./ckpt\\weights-improvement-182-0.84.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6572 - accuracy: 0.8449\n",
      "Epoch 183/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6517 - accuracy: 0.8449\n",
      "Epoch 00183: saving model to ./ckpt\\weights-improvement-183-0.84.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6517 - accuracy: 0.8449\n",
      "Epoch 184/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.6425 - accuracy: 0.8489\n",
      "Epoch 00184: saving model to ./ckpt\\weights-improvement-184-0.85.hdf5\n",
      "783/783 [==============================] - 21s 26ms/step - loss: 0.6422 - accuracy: 0.8488\n",
      "Epoch 185/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.6393 - accuracy: 0.8475\n",
      "Epoch 00185: saving model to ./ckpt\\weights-improvement-185-0.85.hdf5\n",
      "783/783 [==============================] - 20s 26ms/step - loss: 0.6391 - accuracy: 0.8476\n",
      "Epoch 186/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.6348 - accuracy: 0.8505\n",
      "Epoch 00186: saving model to ./ckpt\\weights-improvement-186-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6350 - accuracy: 0.8505\n",
      "Epoch 187/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.6397 - accuracy: 0.8485\n",
      "Epoch 00187: saving model to ./ckpt\\weights-improvement-187-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6394 - accuracy: 0.8486\n",
      "Epoch 188/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.6446 - accuracy: 0.8464 ETA: 0s - loss: 0.6449 - accura\n",
      "Epoch 00188: saving model to ./ckpt\\weights-improvement-188-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6443 - accuracy: 0.8464\n",
      "Epoch 189/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.8511\n",
      "Epoch 00189: saving model to ./ckpt\\weights-improvement-189-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6261 - accuracy: 0.8511\n",
      "Epoch 190/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.6276 - accuracy: 0.8505\n",
      "Epoch 00190: saving model to ./ckpt\\weights-improvement-190-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6283 - accuracy: 0.8503\n",
      "Epoch 191/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.6200 - accuracy: 0.8510\n",
      "Epoch 00191: saving model to ./ckpt\\weights-improvement-191-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6200 - accuracy: 0.8510\n",
      "Epoch 192/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.6168 - accuracy: 0.8512\n",
      "Epoch 00192: saving model to ./ckpt\\weights-improvement-192-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6168 - accuracy: 0.8513\n",
      "Epoch 193/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.6309 - accuracy: 0.8480\n",
      "Epoch 00193: saving model to ./ckpt\\weights-improvement-193-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6314 - accuracy: 0.8480\n",
      "Epoch 194/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6227 - accuracy: 0.8499\n",
      "Epoch 00194: saving model to ./ckpt\\weights-improvement-194-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6227 - accuracy: 0.8499\n",
      "Epoch 195/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.6035 - accuracy: 0.8546\n",
      "Epoch 00195: saving model to ./ckpt\\weights-improvement-195-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6037 - accuracy: 0.8546\n",
      "Epoch 196/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.5942 - accuracy: 0.8569\n",
      "Epoch 00196: saving model to ./ckpt\\weights-improvement-196-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5944 - accuracy: 0.8568\n",
      "Epoch 197/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.6023 - accuracy: 0.8567\n",
      "Epoch 00197: saving model to ./ckpt\\weights-improvement-197-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6020 - accuracy: 0.8567\n",
      "Epoch 198/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.6079 - accuracy: 0.8534\n",
      "Epoch 00198: saving model to ./ckpt\\weights-improvement-198-0.85.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.6079 - accuracy: 0.8534\n",
      "Epoch 199/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.5955 - accuracy: 0.8557\n",
      "Epoch 00199: saving model to ./ckpt\\weights-improvement-199-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5959 - accuracy: 0.8556\n",
      "Epoch 200/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.5893 - accuracy: 0.8584\n",
      "Epoch 00200: saving model to ./ckpt\\weights-improvement-200-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5891 - accuracy: 0.8584\n",
      "Epoch 201/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.5859 - accuracy: 0.8585\n",
      "Epoch 00201: saving model to ./ckpt\\weights-improvement-201-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5860 - accuracy: 0.8585\n",
      "Epoch 202/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.5822 - accuracy: 0.8600\n",
      "Epoch 00202: saving model to ./ckpt\\weights-improvement-202-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5827 - accuracy: 0.8600\n",
      "Epoch 203/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.5839 - accuracy: 0.8581\n",
      "Epoch 00203: saving model to ./ckpt\\weights-improvement-203-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5839 - accuracy: 0.8581\n",
      "Epoch 204/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.8572\n",
      "Epoch 00204: saving model to ./ckpt\\weights-improvement-204-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5883 - accuracy: 0.8572\n",
      "Epoch 205/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.5922 - accuracy: 0.8562\n",
      "Epoch 00205: saving model to ./ckpt\\weights-improvement-205-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5922 - accuracy: 0.8562\n",
      "Epoch 206/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.5801 - accuracy: 0.8593\n",
      "Epoch 00206: saving model to ./ckpt\\weights-improvement-206-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5798 - accuracy: 0.8593\n",
      "Epoch 207/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.8642\n",
      "Epoch 00207: saving model to ./ckpt\\weights-improvement-207-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5649 - accuracy: 0.8642\n",
      "Epoch 208/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.8597\n",
      "Epoch 00208: saving model to ./ckpt\\weights-improvement-208-0.86.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 0.5751 - accuracy: 0.8597\n",
      "Epoch 209/500\n",
      "783/783 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.8606\n",
      "Epoch 00209: saving model to ./ckpt\\weights-improvement-209-0.86.hdf5\n",
      "783/783 [==============================] - 19s 24ms/step - loss: 0.5794 - accuracy: 0.8606\n",
      "Epoch 210/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.5673 - accuracy: 0.8640\n",
      "Epoch 00210: saving model to ./ckpt\\weights-improvement-210-0.86.hdf5\n",
      "783/783 [==============================] - 19s 25ms/step - loss: 0.5673 - accuracy: 0.8640\n",
      "Epoch 211/500\n",
      "782/783 [============================>.] - ETA: 0s - loss: 0.5695 - accuracy: 0.8621\n",
      "Epoch 00211: saving model to ./ckpt\\weights-improvement-211-0.86.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 0.5700 - accuracy: 0.8620\n",
      "Epoch 212/500\n",
      "781/783 [============================>.] - ETA: 0s - loss: 0.5637 - accuracy: 0.8632\n",
      "Epoch 00212: saving model to ./ckpt\\weights-improvement-212-0.86.hdf5\n",
      "783/783 [==============================] - 20s 25ms/step - loss: 0.5643 - accuracy: 0.8630\n"
     ]
    }
   ],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "history = model.fit(X_train, X_test, epochs=500, verbose=1, callbacks= [early_stop, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is for Alice_in_Wonderland.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783/783 [==============================] - 13s 16ms/step - loss: 0.5154 - accuracy: 0.8786\n",
      "Training Accuracy: 0.8786\n"
     ]
    }
   ],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "#print(history.history.keys())\n",
    "loss, accuracy = model.evaluate(X_train, X_test, verbose=True)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Alice in wonderland.txt model as its higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "model.save(\"./model/wonderlandgeneration2.0_model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph for Alice in wonderland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "accuracy = history.history['accuracy']\n",
    "epochs = range(1, len(loss)+1)\n",
    "plt.plot(epochs,loss,'y', label = 'Training Loss', color='green')\n",
    "plt.plot(epochs, accuracy, 'y', label='Training Accuracy', color='red')\n",
    "plt.title('Training Loss & Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss & Accuracy')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paragraph 1: ['In a land full of mist your carrier i i do do i', 'd ', ' said alice i will school by some these alive ', ' said alice timidly his head very very by the rest pepper and came mad see can', ' he said what mouse it', ' alice with afraid to white was hastily at written rather rattling to waiting so they got to make the day croquet who i can guess that ', 't a deal of this ', ' but they sat down and much her chin and']\n",
      "\n",
      "Paragraph 2: ['m a caucus let ', ' said this a footman all its door off their hearing either change of great inches made worse than if i', ' said alice these kept all makes me grow up used towards where these ready mentioned towards hunting sad on and mad day used mentioned tone can', 't pepper she walked up and went and follows silence but where was only march its piece going ', 's down said i was those thing ', ' screamed alice who is that i don', ' said the mock turtle alice what glad once don']\n",
      "\n",
      "Paragraph 3: [' close those again i doing so mad me see ', 'm very confusing you dear what again again you', 't day on then notice of themselves ', ' went and on such a way ', ' said and lory and well very timidly but he won', 't let dinah one ', 't feeling to work ']\n",
      "\n",
      "Paragraph 4: [' on half the trembling voice as soon to leave the unrolled the once it suddenly the whole while in a large all over by their faces in his pocket to be a cat and i see and she began all a voice one tulip had unrolled on the pigs tone was on his dream was the creature ', 'd felt ', ' said the speech these help manage processions said and alice mad the words don', ' but when hunting hunting at once managed you know ', 't so well let worry them ', ' then a race i only really ', ' said these these silence had some most height never knew ']\n",
      "\n",
      "Paragraph 5: [' and alice and sighing in a low trembling alice either the whole air in the house has to read that altogether alice just seen to dormouse and said that the game added who would been left at they', ' full every glass went and looked at this somersault and last they looked at it very soon came again i am very tired with no good warning out a william ', 't clever of him will himself in the words ', ' the mock turtle cake cut but she could feel great sudden tears silence under all she soon gently ever spoke let me throw something ', ' said alice a footman said either tea ', ' alice replied on the same of the time and don', ' said the duchess at house towards the king and pigs on a round box off being round but came off but a row of lamps the unrolled uneasily and it ran and ran off all the queen said to hear it to speak but please change whether a bit ']\n"
     ]
    }
   ],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "#in_text = 'This is a warm and sunny place'\n",
    "in_text = 'In a land full of mist'\n",
    "array1 = []\n",
    "array2 = []\n",
    "array3 = []\n",
    "array4 = []\n",
    "array5 = []\n",
    "\n",
    "#uncomment the following two lines if using the saved model\n",
    "model = models.Sequential()\n",
    "model = models.load_model(\"./model/wonderlandgeneration2.0_model.h5\")\n",
    "\n",
    "# generate a fixed number of words, in this case 30 words\n",
    "for _ in range(500):\n",
    "    # encode the text as integer\n",
    "    encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "    # pre-pad sequences to a fixed length\n",
    "    encoded = pad_sequences([encoded], maxlen=max_length - 1, padding='pre')\n",
    "    # predict probabilities for each word\n",
    "\n",
    "\n",
    "    yhat = model.predict(encoded) #yhat contains the probability of each vocabs\n",
    "\n",
    "    # map predicted word index to word\n",
    "    out_word = ''\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "\n",
    "        if index == np.argmax(yhat):\n",
    "            out_word = word\n",
    "            break\n",
    "    # append to input\n",
    "    in_text += ' ' + out_word\n",
    "\n",
    "splat = in_text.split(\"'\")\n",
    "for number, paragraph in enumerate(splat, 1):\n",
    "    if number % 5 == 1:\n",
    "        array1 += [paragraph]\n",
    "    elif number % 5 == 2:\n",
    "        array2 += [paragraph]\n",
    "    elif number % 5 == 3:\n",
    "        array3 += [paragraph]\n",
    "    elif number % 5 == 4:\n",
    "        array4 += [paragraph]\n",
    "    elif number % 5 == 0:\n",
    "        array5 += [paragraph]\n",
    "        \n",
    "print(\"\\nParagraph 1: \" + str(array1))\n",
    "print(\"\\nParagraph 2: \" + str(array2))\n",
    "print(\"\\nParagraph 3: \" + str(array3))\n",
    "print(\"\\nParagraph 4: \" + str(array4))\n",
    "print(\"\\nParagraph 5: \" + str(array5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Paragraph 1: In a land full of mist your carrier i i do do i'm a caucus let ' close those again i doing so mad me see ' on half the trembling voice as soon to leave the unrolled the once it suddenly the whole while in a large all over by their faces in his pocket\n",
      "\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 15) for input Tensor(\"embedding_2_input_5:0\", shape=(None, 15), dtype=float32), but it was called on an input with incompatible shape (None, 14).\n",
      "\n",
      "Paragraph 2: In a land full of mist your carrier i i do do i'm a caucus let ' close those again i doing so mad me see ' on half the trembling voice as soon to leave the unrolled the once it suddenly the whole while in a large all over by their faces in his pocket to having quite impossible to look at it and when one of us use and i declare ' said alice it's always so much about it and fortunately is ' said alice a very somersault on and she came and make herself evidence to all these first day ' thought\n",
      "\n",
      "\n",
      "Paragraph 3: In a land full of mist your carrier i i do do i'm a caucus let ' close those again i doing so mad me see ' on half the trembling voice as soon to leave the unrolled the once it suddenly the whole while in a large all over by their faces in his pocket to having quite impossible to look at it and when one of us use and i declare ' said alice it's always so much about it and fortunately is ' said alice a very somersault on and she came and make herself evidence to all these first day ' thought alice i'm a cat ' on various half those managed their tails questions and sometimes is everything small nursing pepper but arm off filled to once creatures of the grass magpie put only closed top to his who to those ' said alice it's always spoke that my dear and\n",
      "\n",
      "\n",
      "Paragraph 4: In a land full of mist your carrier i i do do i'm a caucus let ' close those again i doing so mad me see ' on half the trembling voice as soon to leave the unrolled the once it suddenly the whole while in a large all over by their faces in his pocket to having quite impossible to look at it and when one of us use and i declare ' said alice it's always so much about it and fortunately is ' said alice a very somersault on and she came and make herself evidence to all these first day ' thought alice i'm a cat ' on various half those managed their tails questions and sometimes is everything small nursing pepper but arm off filled to once creatures of the grass magpie put only closed top to his who to those ' said alice it's always spoke that my dear and right half growing but they said what could manage right lessons she'd this air and i've said ready to tell after sighing alice i've heard wrong again again the race he had up lying round in at once and hard so very wide but soon left courage but was a\n",
      "\n",
      "\n",
      "Paragraph 5: In a land full of mist your carrier i i do do i'm a caucus let ' close those again i doing so mad me see ' on half the trembling voice as soon to leave the unrolled the once it suddenly the whole while in a large all over by their faces in his pocket to having quite impossible to look at it and when one of us use and i declare ' said alice it's always so much about it and fortunately is ' said alice a very somersault on and she came and make herself evidence to all these first day ' thought alice i'm a cat ' on various half those managed their tails questions and sometimes is everything small nursing pepper but arm off filled to once creatures of the grass magpie put only closed top to his who to those ' said alice it's always spoke that my dear and right half growing but they said what could manage right lessons she'd this air and i've said ready to tell after sighing alice i've heard wrong again again the race he had up lying round in at once and hard so very wide but soon left courage but was a guinea pigs sister hand as far into a a trembling but mad watching you don't let directed me towards comes comes comes hated close towards close alice small small suddenly more conversation by five and white two at that he ought to that ' said alice a dodo used up\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Uncomment following lines and fill in the blank wiht your answer\n",
    "\n",
    "#in_text = 'This is a warm and sunny place'\n",
    "in_text = 'In a land full of mist'\n",
    "\n",
    "#uncomment the following two lines if using the saved model\n",
    "model = models.Sequential()\n",
    "model = models.load_model(\"./model/wonderlandgeneration2.0_model.h5\")\n",
    "\n",
    "# generate a fixed number of words, in this case 30 words\n",
    "for i in range(1,6):\n",
    "    for _ in range(50):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # pre-pad sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=max_length - i, padding='pre')\n",
    "        # predict probabilities for each word\n",
    "\n",
    "\n",
    "        yhat = model.predict(encoded) #yhat contains the probability of each vocabs\n",
    "\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "\n",
    "            if index == np.argmax(yhat):\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "    print('\\nParagraph ' + str(i) + ': ' + str(in_text) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
